{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "# Initialize the Earth Engine module\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='osprey')\n",
        "\n",
        "import ast"
      ],
      "metadata": {
        "id": "BqhKFuJc0G4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your Area of Interest (AOI)\n",
        "#AOI = ee.Geometry.Rectangle([91.5847, 26.0934, 91.7847, 26.2934])  # Replace with your coordinates\n",
        "AOI = ee.FeatureCollection('projects/osprey/assets/Megathon_osprey_flood_file')\n",
        "# Function to calculate RFDI and other features\n",
        "\n",
        "def rfdi_fun(img):\n",
        "   # Convert to linear units (power)\n",
        "   pwr = ee.Image(10).pow(img.divide(10)).set('system:time_start', img.get('system:time_start'))\n",
        "\n",
        "   # Calculate RFDI (Radar Forest Disturbance Index)\n",
        "   rfdi = pwr.select('VV').subtract(pwr.select('VH')).divide(pwr.select('VV').add(pwr.select('VH'))).rename('RFDI')\n",
        "\n",
        "   # Calculate VV/VH ratio\n",
        "   VV_VH = img.select('VV').divide(img.select('VH')).rename('VV_VH')\n",
        "\n",
        "   # Calculate RVI (Radar Vegetation Index)\n",
        "   rvi = pwr.expression('4*VH/(VV+VH)', {'VH': pwr.select('VH'), 'VV': pwr.select('VV')}).rename('RVI')\n",
        "\n",
        "   # Add the calculated bands to the image\n",
        "   return img.addBands(rfdi).addBands(VV_VH).addBands(rvi)\n",
        "\n",
        "# Create a list to store statistics for each time period\n",
        "stats_list = []\n",
        "\n",
        "# Set the initial start and end dates\n",
        "start_date = ee.Date('2022-01-01')\n",
        "end_date = ee.Date('2022-12-10')\n",
        "\n",
        "# Define the total duration you want to loop over (in days)\n",
        "total_days = 343  # Change as needed\n",
        "num_intervals = total_days // 7\n",
        "\n",
        "# Loop through the defined number of intervals\n",
        "for i in range(num_intervals + 1):\n",
        "    S1start_date = start_date.advance(i * 7, 'days')\n",
        "    S1end_date = S1start_date.advance(7, 'days')  # 7 days interval\n",
        "\n",
        "    # Fetch the Sentinel-1 ImageCollection for the current period\n",
        "    s1_All = (\n",
        "        ee.ImageCollection('COPERNICUS/S1_GRD')\n",
        "        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "        .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "        .filter(ee.Filter.inList('orbitProperties_pass', ['ASCENDING', 'DESCENDING']))\n",
        "        .filterDate(S1start_date, S1end_date)\n",
        "        .filterBounds(AOI)\n",
        "    )\n",
        "    # Create a composite and apply a filter to reduce noise\n",
        "    S1All = s1_All.map(rfdi_fun).median()\n",
        "    S1_C = ee.Image.cat([S1All.select(['VV', 'VH', 'RFDI'])]).clip(AOI).focalMean(30, 'square', 'meters')\n",
        "\n",
        "    # Calculate features if there's data\n",
        "    if s1_All.size().getInfo() > 0:\n",
        "        s1_image = s1_All.first()\n",
        "        vv = s1_image.select('VV')\n",
        "        vh = s1_image.select('VH')\n",
        "        vv_vh_ratio = vv.divide(vh).rename('VV_VH_ratio')\n",
        "        s1_features = ee.Image.cat([vv, vh, vv_vh_ratio])\n",
        "\n",
        "        # Calculate statistics\n",
        "        stats = s1_features.reduceRegion(reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True), geometry=AOI, scale=10, maxPixels=1e9).getInfo()\n",
        "\n",
        "        # Store the stats along with the start and end dates\n",
        "        stats_list.append({\n",
        "            'start_date': S1start_date.getInfo(),\n",
        "            'end_date': S1end_date.getInfo(),\n",
        "            'VV_mean': stats['VV_mean'],\n",
        "            'VV_stdDev': stats['VV_stdDev'],\n",
        "            'VH_mean': stats['VH_mean'],\n",
        "            'VH_stdDev': stats['VH_stdDev'],\n",
        "            'VV_VH_ratio_mean': stats['VV_VH_ratio_mean'],\n",
        "            'VV_VH_ratio_stdDev': stats['VV_VH_ratio_stdDev'],\n",
        "        })\n",
        "\n",
        "# Convert the stats list to a DataFrame and save as CSV\n",
        "stats_df = pd.DataFrame(stats_list)\n",
        "stats_df.to_csv('sentinel_1_stats.csv', index=False)\n",
        "\n",
        "\n",
        "print(\"Statistics saved to sentinel_1_stats.csv\")\n"
      ],
      "metadata": {
        "id": "ncNX3EGr0HEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def convert_timestamp(timestamp_str):\n",
        "    # Safely evaluate the string as a dictionary using ast.literal_eval\n",
        "    timestamp_dict = ast.literal_eval(timestamp_str)\n",
        "    timestamp_millis = timestamp_dict['value']\n",
        "    return datetime.utcfromtimestamp(timestamp_millis / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "\n",
        "# Load the CSV file\n",
        "input_file = '/content/sentinel_1_stats.csv'\n",
        "output_file = '/content/sentinel_1_stats_final.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Convert 'start_date' and 'end_date' columns\n",
        "df['Start'] = df['start_date'].apply(convert_timestamp)\n",
        "df['end'] = df['end_date'].apply(convert_timestamp)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Converted dates saved to {output_file}\")"
      ],
      "metadata": {
        "id": "VilOqkdU0HHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib  # for saving the model\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/sentinel_1_stats_assam_riverside.csv')\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(columns=['flood','Start', 'end'])\n",
        "y = data['flood']\n",
        "\n",
        "# Perform stratified 80:20 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, stratify=y, random_state=42)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Save the model parameters\n",
        "joblib.dump(log_reg, '/content/logistic_regression_model.pkl')\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = log_reg.predict(X_test)\n",
        "y1_pred = log_reg.predict(X_train)\n",
        "# Evaluate the model\n",
        "train_accuracy = accuracy_score(y_train, y1_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'train Accuracy: {train_accuracy}')\n",
        "print(f'test Accuracy: {test_accuracy}')\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0R8GfeMPHW5",
        "outputId": "959e7fdc-f6ea-4624-d64d-25f617c53d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Accuracy: 0.8833333333333333\n",
            "test Accuracy: 0.8785714285714286\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91        91\n",
            "           1       0.88      0.76      0.81        49\n",
            "\n",
            "    accuracy                           0.88       140\n",
            "   macro avg       0.88      0.85      0.86       140\n",
            "weighted avg       0.88      0.88      0.88       140\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "app ke liye"
      ],
      "metadata": {
        "id": "JFPxO06mRhaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your Area of Interest (AOI)\n",
        "AOI = ee.Geometry.Rectangle([91.5847, 26.0934, 91.7847, 26.2934])  # Replace with your coordinates\n",
        "# Function to calculate RFDI and other features\n",
        "\n",
        "def rfdi_fun(img):\n",
        "   # Convert to linear units (power)\n",
        "   pwr = ee.Image(10).pow(img.divide(10)).set('system:time_start', img.get('system:time_start'))\n",
        "\n",
        "   # Calculate RFDI (Radar Forest Disturbance Index)\n",
        "   rfdi = pwr.select('VV').subtract(pwr.select('VH')).divide(pwr.select('VV').add(pwr.select('VH'))).rename('RFDI')\n",
        "\n",
        "   # Calculate VV/VH ratio\n",
        "   VV_VH = img.select('VV').divide(img.select('VH')).rename('VV_VH')\n",
        "\n",
        "   # Calculate RVI (Radar Vegetation Index)\n",
        "   rvi = pwr.expression('4*VH/(VV+VH)', {'VH': pwr.select('VH'), 'VV': pwr.select('VV')}).rename('RVI')\n",
        "\n",
        "   # Add the calculated bands to the image\n",
        "   return img.addBands(rfdi).addBands(VV_VH).addBands(rvi)\n",
        "\n",
        "# Create a list to store statistics for each time period\n",
        "stats_list = []\n",
        "\n",
        "# Set the initial start and end dates\n",
        "start_date = ee.Date('2022-01-01') #yeh date hoga, jo current date hai uss se 14 din pahle ka, and then make s\n",
        "end_date = ee.Date('2022-12-10') #current date\n",
        "\n",
        "# Define the total duration you want to loop over (in days)\n",
        "total_days = 14 # Change as needed\n",
        "num_intervals = total_days // 7\n",
        "s1_All = (\n",
        "    ee.ImageCollection('COPERNICUS/S1_GRD')\n",
        "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n",
        "    .filter(ee.Filter.inList('orbitProperties_pass', ['ASCENDING', 'DESCENDING']))\n",
        "    .filterDate(S1start_date, S1end_date)\n",
        "    .filterBounds(AOI)\n",
        ")\n",
        "    # Create a composite and apply a filter to reduce noise\n",
        "S1All = s1_All.map(rfdi_fun).median()\n",
        "S1_C = ee.Image.cat([S1All.select(['VV', 'VH', 'RFDI'])]).clip(AOI).focalMean(30, 'square', 'meters')\n",
        "\n",
        "    # Calculate features if there's data\n",
        "if s1_All.size().getInfo() > 0:\n",
        "    s1_image = s1_All.first()\n",
        "    vv = s1_image.select('VV')\n",
        "    vh = s1_image.select('VH')\n",
        "    vv_vh_ratio = vv.divide(vh).rename('VV_VH_ratio')\n",
        "    s1_features = ee.Image.cat([vv, vh, vv_vh_ratio])\n",
        "\n",
        "        # Calculate statistics\n",
        "    stats = s1_features.reduceRegion(reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True), geometry=AOI, scale=10, maxPixels=1e9).getInfo()\n",
        "\n",
        "        # Store the stats along with the start and end dates\n",
        "    stats_list.append({\n",
        "        'start_date': S1start_date.getInfo(),\n",
        "        'end_date': S1end_date.getInfo(),\n",
        "        'VV_mean': stats['VV_mean'],\n",
        "        'VV_stdDev': stats['VV_stdDev'],\n",
        "        'VH_mean': stats['VH_mean'],\n",
        "        'VH_stdDev': stats['VH_stdDev'],\n",
        "        'VV_VH_ratio_mean': stats['VV_VH_ratio_mean'],\n",
        "        'VV_VH_ratio_stdDev': stats['VV_VH_ratio_stdDev'],\n",
        "    })\n",
        "\n",
        "# Convert the stats list to a DataFrame and save as CSV\n",
        "stats_df = pd.DataFrame(stats_list)\n",
        "stats_df.to_csv('sentinel_1_stats.csv', index=False)\n"
      ],
      "metadata": {
        "id": "4QCI-8YePHMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import pandas as pd\n",
        "path = \"path of the test file generated for a particular user\"\n",
        "def predict(model_path, test_data_path):\n",
        "    # Load the model\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "    # Load the test data\n",
        "    data = pd.read_csv(test_data_path)\n",
        "    X_test = data.drop(columns=['','Start', 'end'])\n",
        "    y_test = data['flood']\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(y_pred)\n",
        "\n",
        "# Call the function\n",
        "predict('/content/logistic_regression_model.pkl', path)\n"
      ],
      "metadata": {
        "id": "n8NsfWqShYSZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}